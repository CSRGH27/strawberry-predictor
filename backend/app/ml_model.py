import pandas as pd
import joblib
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error
import numpy as np

def train_biological_model():
    """
    EntraÃ®ne un modÃ¨le pour prÃ©dire la CAPACITÃ‰ BIOLOGIQUE des fraises
    (et non la production observÃ©e)
    """
    
    print("\n" + "="*70)
    print("ðŸŒ± ENTRAÃŽNEMENT DU MODÃˆLE - CAPACITÃ‰ BIOLOGIQUE")
    print("="*70 + "\n")
    
    # ============================================================
    # Ã‰TAPE 1 : Charger le dataset avec capacitÃ© biologique
    # ============================================================
    print("ðŸ“Š Ã‰tape 1/7 : Chargement du dataset...")
    
    df = pd.read_csv('/app/data/ml_dataset_simplified.csv')
    df['date'] = pd.to_datetime(df['date'])
    
    print(f"   âœ… {len(df)} lignes chargÃ©es")
    print(f"   ðŸ“… PÃ©riode : {df['date'].min()} Ã  {df['date'].max()}")
    print(f"   ðŸ“‹ {len(df.columns)} colonnes disponibles")
    print(f"   ðŸŒ± VariÃ©tÃ©s : {df['variety'].unique().tolist()}")
    
    # VÃ©rifier que kg_biological existe
    if 'kg_biological' not in df.columns:
        raise ValueError("âŒ Colonne 'kg_biological' manquante ! ExÃ©cutez d'abord create_ml_dataset_simplified.py")
    
    print(f"   âœ… Colonne 'kg_biological' dÃ©tectÃ©e")
    
    # ============================================================
    # Ã‰TAPE 2 : PrÃ©parer les features
    # ============================================================
    print("\nðŸ”§ Ã‰tape 2/7 : PrÃ©paration des features...")
    
    # Encoder la variÃ©tÃ©
    df['variety_encoded'] = pd.Categorical(df['variety']).codes
    
    # SÃ©lectionner les features importantes
    feature_columns = [
        # ==========================================
        # FEATURES DE BASE
        # ==========================================
        'variety_encoded',      # VariÃ©tÃ© (Clery, Manon, etc.)
        'plants_nbrs',          # Nombre de plants
        
        # ==========================================
        # FEATURES TEMPORELLES (SaisonnalitÃ©)
        # ==========================================
        'month',                # Mois (1-12)
        'week_of_year',         # Semaine de l'annÃ©e (1-52)
        'day_of_year',          # Jour de l'annÃ©e (1-365)
        'day_of_week',          # Jour de la semaine (0-6)
        'days_since_season_start',  # â­ TRÃˆS IMPORTANT - Phase de maturation
        
        # ==========================================
        # MÃ‰TÃ‰O DU JOUR (Conditions actuelles)
        # ==========================================
        'temperature_mean',     # TempÃ©rature moyenne du jour
        'humidity_mean',        # HumiditÃ© moyenne du jour
        'precipitation',        # PrÃ©cipitations du jour
        'sunshine_duration',    # Ensoleillement du jour
        'solar_radiation',      # Rayonnement solaire du jour
        
        # ==========================================
        # MÃ‰TÃ‰O SUR 7 JOURS (Tendances)
        # ==========================================
        'temp_mean_7d',         # TempÃ©rature moyenne 7 derniers jours
        'humidity_mean_7d',     # HumiditÃ© moyenne 7 derniers jours
        'precipitation_7d_sum', # PrÃ©cipitations cumulÃ©es 7j
        'sunshine_7d_sum',      # Ensoleillement cumulÃ© 7j
        'solar_radiation_7d_mean', # Rayonnement solaire moyen 7j
        
        # ==========================================
        # CHANGEMENTS MÃ‰TÃ‰O (Chocs/Variations)
        # ==========================================
        'temp_delta',           # Changement de tempÃ©rature vs moyenne 7j
        
        # ==========================================
        # PRODUCTION PASSÃ‰E (Tendances biologiques)
        # ==========================================
        'kg_biological_prev_day',   # â­ CapacitÃ© biologique jour prÃ©cÃ©dent
        'kg_biological_7d_mean',    # â­ CapacitÃ© moyenne 7 derniers jours
        'kg_biological_14d_mean',   # â­ CapacitÃ© moyenne 14 derniers jours
        
        # ==========================================
        # RENDEMENT
        # ==========================================
        'kg_per_plant'          # Production par plant
    ]
    
    # VÃ©rifier que toutes les colonnes existent
    missing_cols = [col for col in feature_columns if col not in df.columns]
    if missing_cols:
        print(f"   âš ï¸  Colonnes manquantes : {missing_cols}")
        print(f"   ðŸ“‹ Colonnes disponibles : {df.columns.tolist()}")
        feature_columns = [col for col in feature_columns if col in df.columns]
    
    print(f"   âœ… {len(feature_columns)} features sÃ©lectionnÃ©es")
    
    # Features (X) et cible (y)
    X = df[feature_columns]
    y = df['kg_biological']  # â­ CIBLE = CAPACITÃ‰ BIOLOGIQUE
    
    print(f"\n   ðŸŽ¯ TARGET : kg_biological")
    print(f"      Moyenne : {y.mean():.2f} kg")
    print(f"      Min     : {y.min():.2f} kg")
    print(f"      Max     : {y.max():.2f} kg")
    
    # ============================================================
    # Ã‰TAPE 3 : SÃ©parer en train/test (temporel)
    # ============================================================
    print("\nâœ‚ï¸  Ã‰tape 3/7 : SÃ©paration train/test...")
    
    # Option 1 : Split temporel (recommandÃ© pour les sÃ©ries temporelles)
    # Les 80% les plus anciennes pour train, les 20% les plus rÃ©centes pour test
    df_sorted = df.sort_values('date')
    split_idx = int(len(df_sorted) * 0.8)
    
    X_train = X.iloc[:split_idx]
    X_test = X.iloc[split_idx:]
    y_train = y.iloc[:split_idx]
    y_test = y.iloc[split_idx:]
    
    print(f"   âœ… Train : {len(X_train)} lignes (jusqu'Ã  {df_sorted.iloc[split_idx-1]['date'].date()})")
    print(f"   âœ… Test  : {len(X_test)} lignes (Ã  partir de {df_sorted.iloc[split_idx]['date'].date()})")
    
    # Option 2 : Split alÃ©atoire (dÃ©commenter si vous prÃ©fÃ©rez)
    # X_train, X_test, y_train, y_test = train_test_split(
    #     X, y, test_size=0.2, random_state=42, shuffle=True
    # )
    
    # ============================================================
    # Ã‰TAPE 4 : Tester plusieurs modÃ¨les
    # ============================================================
    print("\nðŸŒ³ Ã‰tape 4/7 : Test de plusieurs algorithmes...")
    
    models = {
        'Random Forest': RandomForestRegressor(
            n_estimators=200,        # Nombre d'arbres
            max_depth=15,            # Profondeur maximale
            min_samples_split=5,     # Min Ã©chantillons pour split
            min_samples_leaf=2,      # Min Ã©chantillons par feuille
            random_state=42,
            n_jobs=-1                # Utiliser tous les CPU
        ),
        'Gradient Boosting': GradientBoostingRegressor(
            n_estimators=200,
            max_depth=8,
            learning_rate=0.05,
            min_samples_split=5,
            random_state=42
        )
    }
    
    best_model = None
    best_score = float('inf')
    best_name = ''
    
    results = {}
    
    for name, model in models.items():
        print(f"\n   ðŸ”„ Test de {name}...")
        
        # EntraÃ®ner
        model.fit(X_train, y_train)
        
        # PrÃ©dire
        y_pred = model.predict(X_test)
        
        # MÃ©triques
        mae = mean_absolute_error(y_test, y_pred)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        r2 = r2_score(y_test, y_pred)
        
        # Erreur relative (en %)
        mask_non_zero = y_test > 0
        if mask_non_zero.sum() > 0:
            mape = np.mean(np.abs((y_test[mask_non_zero] - y_pred[mask_non_zero]) / y_test[mask_non_zero])) * 100
        else:
            mape = 0
        
        # Cross-validation sur le train
        cv_scores = cross_val_score(model, X_train, y_train, 
                                     cv=5, 
                                     scoring='neg_mean_absolute_error',
                                     n_jobs=-1)
        cv_mae = -cv_scores.mean()
        
        results[name] = {
            'mae': mae,
            'rmse': rmse,
            'r2': r2,
            'mape': mape,
            'cv_mae': cv_mae
        }
        
        print(f"      MAE  : {mae:.2f} kg")
        print(f"      RMSE : {rmse:.2f} kg")
        print(f"      RÂ²   : {r2:.3f}")
        print(f"      MAPE : {mape:.2f}%")
        print(f"      CV MAE: {cv_mae:.2f} kg (validation croisÃ©e)")
        
        # Garder le meilleur
        if mae < best_score:
            best_score = mae
            best_model = model
            best_name = name
    
    print(f"\n   ðŸ† Meilleur modÃ¨le : {best_name} (MAE: {best_score:.2f} kg)")
    
    # ============================================================
    # Ã‰TAPE 5 : Analyser le meilleur modÃ¨le
    # ============================================================
    print(f"\nðŸ“ˆ Ã‰tape 5/7 : Analyse du modÃ¨le {best_name}...")
    
    y_pred_best = best_model.predict(X_test)
    
    # Importance des features
    if hasattr(best_model, 'feature_importances_'):
        feature_importance = pd.DataFrame({
            'feature': feature_columns,
            'importance': best_model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        print("\n   ðŸ” Top 15 features les plus importantes :")
        for idx, row in feature_importance.head(15).iterrows():
            print(f"      {row['feature']:<35} {row['importance']:.4f}")
    
    # Analyse des erreurs
    errors = np.abs(y_test.values - y_pred_best)
    print(f"\n   ðŸ“Š Analyse des erreurs :")
    print(f"      Erreur moyenne    : {errors.mean():.2f} kg")
    print(f"      Erreur mÃ©diane    : {np.median(errors):.2f} kg")
    print(f"      Erreur max        : {errors.max():.2f} kg")
    print(f"      90% des erreurs < : {np.percentile(errors, 90):.2f} kg")
    
    # ============================================================
    # Ã‰TAPE 6 : Convertir les prÃ©dictions biologiques en production rÃ©elle
    # ============================================================
    print(f"\nðŸ”„ Ã‰tape 6/7 : Conversion capacitÃ© biologique â†’ production rÃ©elle...")
    
    # RÃ©cupÃ©rer les donnÃ©es de test avec day_of_week
    test_data = df.iloc[split_idx:].copy()
    test_data['kg_biological_pred'] = y_pred_best
    
    # Mapper day_of_week â†’ harvest_fraction
    harvest_fraction_map = {
        0: 1/3,  # Lundi
        1: 1/3,  # Mardi
        2: 1/3,  # Mercredi
        3: 1/2,  # Jeudi
        4: 1/2,  # Vendredi
        5: 1/2,  # Samedi
        6: 0     # Dimanche (ne devrait pas exister aprÃ¨s filtrage)
    }
    
    test_data['harvest_fraction'] = test_data['day_of_week'].map(harvest_fraction_map)
    
    # Convertir capacitÃ© biologique â†’ production observÃ©e
    test_data['kg_produced_pred'] = test_data['kg_biological_pred'] * test_data['harvest_fraction']
    
    # Comparer avec la production rÃ©elle observÃ©e
    mae_observed = mean_absolute_error(test_data['kg_produced'], test_data['kg_produced_pred'])
    r2_observed = r2_score(test_data['kg_produced'], test_data['kg_produced_pred'])
    
    print(f"   ðŸ“Š Performance sur production OBSERVÃ‰E (kg_produced) :")
    print(f"      MAE  : {mae_observed:.2f} kg")
    print(f"      RÂ²   : {r2_observed:.3f}")
    
    # ============================================================
    # Ã‰TAPE 7 : Sauvegarder le modÃ¨le
    # ============================================================
    print(f"\nðŸ’¾ Ã‰tape 7/7 : Sauvegarde du modÃ¨le...")
    
    model_data = {
        'model': best_model,
        'model_name': best_name,
        'feature_columns': feature_columns,
        'variety_mapping': dict(enumerate(df['variety'].unique())),
        'harvest_fraction_map': harvest_fraction_map,
        'metrics': results[best_name],
        'metrics_observed': {
            'mae': mae_observed,
            'r2': r2_observed
        },
        'trained_on': pd.Timestamp.now().isoformat(),
        'target': 'kg_biological',  # Important : indique ce que prÃ©dit le modÃ¨le
        'note': 'Ce modÃ¨le prÃ©dit kg_biological. Pour obtenir kg_produced, multiplier par harvest_fraction.'
    }
    
    joblib.dump(model_data, '/app/data/strawberry_biological_model.pkl')
    
    print(f"   âœ… ModÃ¨le sauvegardÃ© : /app/data/strawberry_biological_model.pkl")
    
    # ============================================================
    # EXEMPLES DE PRÃ‰DICTIONS
    # ============================================================
    print("\n" + "="*70)
    print("ðŸ”® EXEMPLES DE PRÃ‰DICTIONS")
    print("="*70)
    
    # Prendre les 10 premiers exemples du test
    sample = test_data.head(10)
    
    comparison = pd.DataFrame({
        'Date': sample['date'].dt.strftime('%Y-%m-%d'),
        'Jour': sample['day_of_week'].map({0:'Lun', 1:'Mar', 2:'Mer', 3:'Jeu', 4:'Ven', 5:'Sam', 6:'Dim'}),
        'VariÃ©tÃ©': sample['variety'],
        'CapacitÃ© bio rÃ©elle': sample['kg_biological'].round(1),
        'CapacitÃ© bio prÃ©dite': sample['kg_biological_pred'].round(1),
        'Erreur bio (kg)': (sample['kg_biological_pred'] - sample['kg_biological']).round(1),
        'Prod. observÃ©e': sample['kg_produced'].round(1),
        'Prod. prÃ©dite': sample['kg_produced_pred'].round(1)
    })
    
    print("\n" + comparison.to_string(index=False))
    
    # ============================================================
    # RÃ‰SUMÃ‰ FINAL
    # ============================================================
    print("\n" + "="*70)
    print("ðŸ“Š RÃ‰SUMÃ‰ DU MODÃˆLE")
    print("="*70)
    print(f"\nðŸŽ¯ TARGET : CapacitÃ© biologique (kg_biological)")
    print(f"   â†’ Ce que produiraient TOUS les plants si rÃ©coltÃ©s")
    print(f"\nðŸ“ˆ Performance sur capacitÃ© biologique :")
    print(f"   MAE  : {best_score:.2f} kg")
    print(f"   RMSE : {results[best_name]['rmse']:.2f} kg")
    print(f"   RÂ²   : {results[best_name]['r2']:.3f}")
    print(f"   MAPE : {results[best_name]['mape']:.2f}%")
    print(f"\nðŸ“Š Performance sur production observÃ©e (aprÃ¨s conversion) :")
    print(f"   MAE  : {mae_observed:.2f} kg")
    print(f"   RÂ²   : {r2_observed:.3f}")
    print(f"\nðŸ’¡ UTILISATION :")
    print(f"   1. Le modÃ¨le prÃ©dit kg_biological")
    print(f"   2. Pour obtenir la production Ã  rÃ©colter :")
    print(f"      â€¢ Lundi/Mardi/Mercredi : kg_biological Ã— 1/3")
    print(f"      â€¢ Jeudi/Vendredi : kg_biological Ã— 1/2")
    print("="*70 + "\n")
    
    return best_model, feature_columns, results, test_data

if __name__ == "__main__":
    train_biological_model()